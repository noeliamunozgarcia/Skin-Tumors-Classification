{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.data.dataset import SkinDataset\n",
    "from src.utils.config import Config\n",
    "from src.utils.utils import merge_metadata_label, get_dataset_mean_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = Config.get_path('images')\n",
    "GROUND_TRUTH_PATH = Config.get_path('ground_truth_csv')\n",
    "METADATA_PATH = Config.get_path('metadata_csv')\n",
    "\n",
    "MERGED_DATASET_PATH = Config.get_path('merged_dataset_csv')\n",
    "CLEAN_DATASET_PATH = Config.get_path('clean_dataset_csv')\n",
    "\n",
    "TRAINING_PATH = Config.get_path('training_csv')\n",
    "TEST_PATH = Config.get_path('test_csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each metadata sample, I add the ``label`` field. This field is taken from the corresponding row of the ground truth CSV. <br/>\n",
    "I remove ``lesion_id`` attribute from metadata attributes. <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the Initial Dataset: 25331\n"
     ]
    }
   ],
   "source": [
    "metadata = read_csv('C:/Users/UX534/ISIC-2019-v2/data/raw/ISIC_2019_Training_Metadata.csv', usecols=['image', 'age_approx', 'anatom_site_general', 'sex'])\n",
    "diagnoses = read_csv('C:/Users/UX534/ISIC-2019-v2/data/raw/ISIC_2019_Training_GroundTruth.csv')\n",
    "\n",
    "dataset = merge_metadata_label(metadata, diagnoses)\n",
    "dataset.to_csv('C:/Users/UX534/ISIC-2019-v2/data/raw/ISIC_2019_Merged_dataset.csv', encoding='utf-8', index=False)\n",
    "\n",
    "print('Size of the Initial Dataset:', len(dataset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I remove all rows with any empty cells.<br/>\n",
    "Samples of classes we are not interested in are also removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the Clean Dataset: 19080\n"
     ]
    }
   ],
   "source": [
    "dataset.dropna(subset=['age_approx', 'anatom_site_general', 'sex'], inplace=True)\n",
    "dataset.index.name = 'index'\n",
    "\n",
    "for forbidden_label in ['BKL', 'AK', 'VASC']:\n",
    "    dataset.drop(dataset[dataset['label'] == forbidden_label].index, inplace = True)\n",
    "\n",
    "dataset.to_csv('C:/Users/UX534/ISIC-2019-v2/data/interim/ISIC_2019_dataset_clean.csv', encoding='utf-8')\n",
    "\n",
    "print('Size of the Clean Dataset:', len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train the classifier, is necessary to normalize images.<br/>\n",
    "They must have zero average, and unit standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset images mean: [0.5949144093096469, 0.5940122161980812, 0.5965893571793713]\n",
      "Dataset images standard deviation: [0.0806834955201987, 0.08093546973609639, 0.0811099191136179]\n"
     ]
    }
   ],
   "source": [
    "dset = SkinDataset('C:/Users/UX534/ISIC-2019-v2/data/images/', 'C:/Users/UX534/ISIC-2019-v2/data/interim/ISIC_2019_dataset_clean.csv', transforms.ToTensor())\n",
    "dataset_loader = DataLoader(dset, pin_memory=True)\n",
    "mean, std_dev = get_dataset_mean_std(dataset_loader)\n",
    "\n",
    "print('Dataset images mean:', mean)\n",
    "print('Dataset images standard deviation:', std_dev)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I split the dataset into **Training Set** [85%], and **Test Set** [15%]. <br/>\n",
    "Obviously, the split is totally random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Size: 16218\n",
      "Test Set Size: 2862\n"
     ]
    }
   ],
   "source": [
    "tr, te = train_test_split(dataset, train_size=0.85, shuffle=True)\n",
    "\n",
    "tr.to_csv('C:/Users/UX534/ISIC-2019-v2/data/processed/ISIC_2019_dataset_train.csv', encoding='utf-8')\n",
    "te.to_csv('C:/Users/UX534/ISIC-2019-v2/data/processed/ISIC_2019_dataset_test.csv', encoding='utf-8')\n",
    "\n",
    "print('Training Set Size:', len(tr))\n",
    "print('Test Set Size:', len(te))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
